from pathlib import Path
import re
import pickle


from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_classic.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

from loaders import load_web_page, load_pdf
from preprosess import (
    clean_text, 
    dedupe_by_embedding, 
    filter_and_dedup, 
)



EMBED_MODEL_NAME = "cointegrated/rubert-tiny2"
# EMBED_MODEL = "intfloat/multilingual-e5-small"


def create_db():
    """Create optimized vector database with BM25 index"""
    html_docs = load_web_page()
    pdf_docs = load_pdf()

    all_docs = html_docs + pdf_docs

    # cleaning
    for doc in all_docs:
        doc.page_content = clean_text(doc.page_content)

    embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)
    all_docs_filtered = dedupe_by_embedding(filter_and_dedup(all_docs), embedding_model=embedding_model)
    
    print(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_docs_filtered)}")

    # OPTIMIZED: Larger chunks with overlap for better context
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""],
    )
    
    splitted_docs = text_splitter.split_documents(all_docs_filtered)
    print(f"–ë—ã–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_docs_filtered)}, —Å—Ç–∞–ª–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(splitted_docs)}")
    
    # Show sample chunk for verification
    if splitted_docs:
        print(f"\n–ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):\n{splitted_docs[0].page_content[:200]}...")
        print(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞: {splitted_docs[0].metadata}")    
    
    # Create semantic search index (FAISS)
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (FAISS)...")
    embed_model = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    vector_store = FAISS.from_documents(splitted_docs, embed_model)
    vector_store.save_local("data/tea_index")
    print("FAISS –∏–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    # Create BM25 keyword index
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ BM25 –∏–Ω–¥–µ–∫—Å–∞ (keyword search)...")
    bm25_retriever = BM25Retriever.from_documents(splitted_docs)
    bm25_retriever.k = 3  # Return top 3 results by default
    
    # Save BM25 index
    with open("data/bm25_index.pkl", "wb") as f:
        pickle.dump(bm25_retriever, f)
    print("BM25 –∏–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    print("\n‚úÖ –û–±–µ –±–∞–∑—ã —Å–æ–∑–¥–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/")
    return vector_store, bm25_retriever

def load_db():
    """Load both FAISS and BM25 indexes"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤...")
    
    # Load FAISS
    embed_model = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    vector_store = FAISS.load_local(
        "data/tea_index", 
        embed_model, 
        allow_dangerous_deserialization=True
    )
    
    # Load BM25
    with open("data/bm25_index.pkl", "rb") as f:
        bm25_retriever = pickle.load(f)
    
    print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    return vector_store, bm25_retriever

def hybrid_search(vector_store: FAISS, bm25_retriever: BM25Retriever, 
                  query: str, k: int = 3, bm25_weight: float = 0.5):
    """
    Hybrid search combining BM25 (keyword) and semantic search
    
    Args:
        bm25_weight: 0.0 = pure semantic, 1.0 = pure BM25, 0.5 = balanced
    """
    # Create retrievers
    semantic_retriever = vector_store.as_retriever(search_kwargs={"k": k})
    
    # Combine with EnsembleRetriever
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, semantic_retriever],
        weights=[bm25_weight, 1 - bm25_weight]  # BM25 weight, Semantic weight
    )
    
    # Get results
    docs = ensemble_retriever.invoke(query)
    return docs[:k]  # Return top k

def db_lookup(vector_store: FAISS, bm25_retriever: BM25Retriever, 
              query: str, k: int = 3, mode: str = 'hybrid', max_to_output: int = 700):
    """
    Search with different modes
    
    Args:
        mode: 'hybrid' (default), 'semantic', 'bm25'
    """
    print(f"\n{'='*50} üîç –ü–û–ò–°–ö {'='*50}")
    print(f"üìù –ó–∞–ø—Ä–æ—Å: {query}")
    print(f"üéØ –†–µ–∂–∏–º: {mode.upper()}")
    print(f"{'='*70}\n")
    
    if mode == 'hybrid':
        # Hybrid: 60% BM25 + 40% semantic (favor keywords for tea names)
        docs_found = hybrid_search(vector_store, bm25_retriever, query, k=k, bm25_weight=0.6)
        # Convert to list of (doc, None) tuples for consistent handling
        docs_found = [(doc, None) for doc in docs_found]
        
    elif mode == 'bm25':
        # Pure keyword search
        bm25_retriever.k = k
        docs = bm25_retriever.invoke(query)
        docs_found = [(doc, None) for doc in docs]
        
    elif mode == 'semantic':
        # Pure semantic search with scores
        docs_found = vector_store.similarity_search_with_score(query, k=k)
    
    else:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {mode}")
        return
    
    # Display results
    for i, doc_tuple in enumerate(docs_found, 1):
        doc = doc_tuple[0]
        score = doc_tuple[1] if len(doc_tuple) > 1 and doc_tuple[1] is not None else None
        
        # Add ranking emojis
        rank_emoji = {1: "ü•á", 2: "ü•à", 3: "ü•â"}.get(i, f"#{i}")
        print(f"{rank_emoji} –†–µ–∑—É–ª—å—Ç–∞—Ç {i}", end="")
        if score is not None:
            print(f" (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.4f})", end="")
        print()
        
        source_type = doc.metadata.get('source_type', 'unknown')
        topic = doc.metadata.get('topic', 'unknown')
        source_emoji = {"web": "üåê", "pdf": "üìÑ"}.get(source_type, "‚ùì")
        topic_emoji = {"brewing_guide": "‚òï", "tea_types": "üçµ"}.get(topic, "üìã")
        print(f"{source_emoji} –ò—Å—Ç–æ—á–Ω–∏–∫: {doc.metadata.get('source_type', 'unknown')} | "
              f"{topic_emoji} –¢–µ–º–∞: {doc.metadata.get('topic', 'unknown')}")
        if 'page' in doc.metadata:
            print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞: {doc.metadata['page']}")
        print(f"üìã –ü–æ–ª–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {doc.metadata}")
        
        # Highlight query terms for BM25/hybrid
        content = doc.page_content[:max_to_output]
        
        query_terms = query.lower().split()
        for term in query_terms:
            if len(term) > 2:  # Skip short words                    
                content = re.sub(
                    f'({re.escape(term)})',
                    r'üî•\1üî•',
                    content,
                    flags=re.IGNORECASE
                )
        
        print(f"\nüìñ –¢–µ–∫—Å—Ç ({len(doc.page_content)} —Å–∏–º–≤–æ–ª–æ–≤):")
        print(content)
        if len(doc.page_content) > max_to_output:
            print(f"‚úÇÔ∏è ... [–ø–æ–∫–∞–∑–∞–Ω–æ {max_to_output} –∏–∑ {len(doc.page_content)} —Å–∏–º–≤–æ–ª–æ–≤]")
        print(f"\n{'-'*50} üåü {'-'*50}\n")

def compare_modes(vector_store: FAISS, bm25_retriever: BM25Retriever, query: str):
    """Compare all three search modes"""
    print(f"\n{'#'*40} üîÑ –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ñ–ò–ú–û–í {'#'*40}")
    print(f"üìä –î–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
    print(f"{'#'*70}")
    
    for mode in ['bm25', 'semantic', 'hybrid']:
        db_lookup(vector_store, bm25_retriever, query, k=2, mode=mode, max_to_output=700)
        if mode != 'hybrid':
            input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–µ–∂–∏–º–∞...")

def test_queries(vector_store: FAISS, bm25_retriever: BM25Retriever):
    """Test with sample queries including tea names"""
    test_cases = [
        ("–≥–∞–π–≤–∞–Ω—å", "hybrid"),
        ("–ñ–µ–ª–µ–∑–Ω–∞—è –±–æ–≥–∏–Ω—è –º–∏–ª–æ—Å–µ—Ä–¥–∏—è", "hybrid"),
        ("–∫–∞–∫ –∑–∞–≤–∞—Ä–∏–≤–∞—Ç—å –±–µ–ª—ã–π —á–∞–π", "semantic"),
        ("—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤–æ–¥—ã –¥–ª—è –∑–µ–ª–µ–Ω–æ–≥–æ —á–∞—è", "semantic"),
    ]
    
    print("\n" + "="*45 + " üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï " + "="*45)
    print("üéØ –ö–ê–ß–ï–°–¢–í–ê –ü–û–ò–°–ö–ê")
    print("="*70)
    
    for query, mode in test_cases:
        print(f"\nüß™ –¢–µ—Å—Ç: '{query}' (—Ä–µ–∂–∏–º: {mode.upper()})")
        db_lookup(vector_store, bm25_retriever, query, k=2, mode=mode, max_to_output=700)
        input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...")

def main():
    # Check if both indexes exist
    faiss_exists = Path("data/tea_index").exists()
    bm25_exists = Path("data/bm25_index.pkl").exists()
    
    if not (faiss_exists and bm25_exists):
        print("‚ö†Ô∏è  –ò–Ω–¥–µ–∫—Å—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, —Å–æ–∑–¥–∞—ë–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        vector_store, bm25_retriever = create_db()
        
        # Run tests after creation
        print("\n" + "="*70)
        response = input("–•–æ—Ç–∏—Ç–µ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É? (y/n): ").strip().lower()
        if response == 'y':
            test_queries(vector_store, bm25_retriever)
    else:
        print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        vector_store, bm25_retriever = load_db()

    # Interactive mode
    print("\n" + "="*45 + " üçµ –ì–ò–ë–†–ò–î–ù–´–ô –ü–û–ò–°–ö " + "="*45)
    print("üéÆ –î–û–°–¢–£–ü–ù–´–ï –†–ï–ñ–ò–ú–´:")
    print("  üîÑ 'hybrid:–∑–∞–ø—Ä–æ—Å'   - BM25 + —Å–µ–º–∞–Ω—Ç–∏–∫–∞ (–¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π —á–∞—è)")
    print("  üîç 'bm25:–∑–∞–ø—Ä–æ—Å'     - —Ç–æ–ª—å–∫–æ keyword search")
    print("  üß† 'semantic:–∑–∞–ø—Ä–æ—Å' - —Ç–æ–ª—å–∫–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫")
    print("  üìä 'compare:–∑–∞–ø—Ä–æ—Å'  - —Å—Ä–∞–≤–Ω–∏—Ç—å –≤—Å–µ —Ä–µ–∂–∏–º—ã")
    print("  ‚ö° '–∑–∞–ø—Ä–æ—Å'          - semantic –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    print("="*70)
    print("üí¨ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú (Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    print("="*70)
    
    while True:
        try:
            user_input = input("\n–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\n\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break
        
        if not user_input:
            continue
        
        # Parse mode if specified
        if ':' in user_input:
            parts = user_input.split(':', 1)
            if parts[0].strip() in ['hybrid', 'bm25', 'semantic', 'compare']:
                mode = parts[0].strip()
                query = parts[1].strip()
            else:
                mode = 'semantic'
                query = user_input
        else:
            mode = 'semantic'
            query = user_input
        
        if mode == 'compare':
            compare_modes(vector_store, bm25_retriever, query)
        else:
            db_lookup(vector_store, bm25_retriever, query, k=3, mode=mode, max_to_output=700)

if __name__ == "__main__":
    main()
