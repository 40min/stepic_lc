import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage
import tiktoken

load_dotenv()
MODEL = os.getenv("OPENAI_API_MODEL", "gpt-5")

llm = ChatOpenAI(model_name=MODEL, temperature=0.9)

# –ö–∞—Å—Ç–æ–º–Ω–∞—è –ø–∞–º—è—Ç—å —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
class MemoryWithSystemPrepend(BaseChatMessageHistory):
    def __init__(self, system_prompt: str, max_tokens: int = 4000):
        self.system_prompt = system_prompt
        self._messages = []  # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –¥–∏–∞–ª–æ–≥ (–±–µ–∑ system)
        self.max_tokens = max_tokens
        self.encoder = tiktoken.get_encoding("cl100k_base")

    def count_tokens(self, messages):
            total = 0
            for msg in messages:
                total += len(self.encoder.encode(msg.content))
            return total
    
    @property
    def messages(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏: prepend system + —É—Å–µ—á–µ–Ω–∏–µ –¥–æ max_tokens"""
        history = [SystemMessage(content=self.system_prompt)] + self._messages
        
        while self.count_tokens(history) > self.max_tokens and len(history) > 1:
            history.pop(1)

        return history

    def add_message(self, message: BaseMessage):
        if not isinstance(message, SystemMessage):
            self._messages.append(message) # –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –≤ –¥–∏–∞–ª–æ–≥

    def clear(self):
        self._messages = []


# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
support_memory = MemoryWithSystemPrepend("–¢—ã –æ–ø—ã—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞. –¢—ã –≤—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤ –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª–µ–Ω. –û—Ç–≤–µ—á–∞–π –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ 100 —Å–∏–º–≤–æ–ª–æ–≤.")
client_memory = MemoryWithSystemPrepend("–¢—ã —Ä–∞–∑–¥—Ä–∞–∂—ë–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —É –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç. –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –≥—Ä—É–±—ã–π. –û—Ç–≤–µ—á–∞–π –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ 100 —Å–∏–º–≤–æ–ª–æ–≤.")

# –ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç –±–µ–∑ RunnableWithMessageHistory –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
def simple_chat(user_input: str, memory: MemoryWithSystemPrepend):
    memory.add_message(HumanMessage(content=user_input))
    response = llm.invoke(memory.messages)
    memory.add_message(response)
    
    return response.content

# –î–µ–º–æ: –¥–ª–∏–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥
response = "–£ –º–µ–Ω—è –∑–∞ 3 –≥–æ–¥–∞ –Ω–µ –±—ã–ª–æ —Ä–∞–∑—Ä—ã–≤–æ–≤, –∞ —Ç—É—Ç –°–†–ê–ó–£ –¢–†–ò –†–ê–ó–†–´–í–ê!!!"
print('[1] –ö–ª–∏–µ–Ω—Ç:', response)

for i in range(12):
    response = simple_chat(response, support_memory)
    print(f"[{i+1}] –ü–æ–¥–¥–µ—Ä–∂–∫–∞: {response}\n")
    response = simple_chat(response, client_memory)
    print(f"[{i+2}] –ö–ª–∏–µ–Ω—Ç: {response}")

print("\nüìä –ß—Ç–æ –≤–∏–¥–∏—Ç –º–æ–¥–µ–ª—å (–ø–µ—Ä–≤—ã–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏):")
for msg in support_memory.messages[:6]:
    print(f"  - {msg.__class__.__name__}: {msg.content[:50]}...")
    
print(f"\nüíæ –†–µ–∞–ª—å–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏–π: {len(support_memory._messages)}")
print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ –º–æ–¥–µ–ª—å —Å–æ–æ–±—â–µ–Ω–∏–π (+ system): {len(support_memory.messages)}")
